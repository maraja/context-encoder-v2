{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"ALBERT Fine-Tune.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0621d8d6cf004e8fb3441b21a298a991":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_73fa7176d55b43d189c9f60de955db00","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_78b4502a58f54ed8b1cdd997692b187a","IPY_MODEL_6b147f42a11442dd9f95f2e8b02c6fbf"]}},"73fa7176d55b43d189c9f60de955db00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78b4502a58f54ed8b1cdd997692b187a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_036d201c15cc4dcb849b289184524f11","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":760289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_773a3c034c5541beaaec6b6c86ec78c0"}},"6b147f42a11442dd9f95f2e8b02c6fbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c71b2d518a764324bc12f5caaa99c155","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 760k/760k [00:01&lt;00:00, 380kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_66dc6460fa72474f93d1b8141ff0fe31"}},"036d201c15cc4dcb849b289184524f11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"773a3c034c5541beaaec6b6c86ec78c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c71b2d518a764324bc12f5caaa99c155":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"66dc6460fa72474f93d1b8141ff0fe31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ad341d982094dd08aa260e292e17995":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9acb8cdd66144efd84f6fad4ef781844","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b436fa0276b94ef9bf5843b5da92049e","IPY_MODEL_a36cfe270c664054b99b695b0088552b"]}},"9acb8cdd66144efd84f6fad4ef781844":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b436fa0276b94ef9bf5843b5da92049e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7fd08ad5f2fb44608f1c95d6dfedd36d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1312669,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1312669,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acddb2ca9d1c4ba0aa37061ef196aa1a"}},"a36cfe270c664054b99b695b0088552b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4108fd104a5f451fa1273e98957f7507","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.31M/1.31M [00:02&lt;00:00, 634kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7470da67fe504782b73e021fd2c6e98e"}},"7fd08ad5f2fb44608f1c95d6dfedd36d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"acddb2ca9d1c4ba0aa37061ef196aa1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4108fd104a5f451fa1273e98957f7507":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7470da67fe504782b73e021fd2c6e98e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4d92118c0e04b58bc67a45eb6fdf785":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_803abee7e8494d638704197a0651d08e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5139396a570544079a9f9ed498a51e8a","IPY_MODEL_6577f633bf9f4342bf6181b4e27697ee"]}},"803abee7e8494d638704197a0651d08e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5139396a570544079a9f9ed498a51e8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b589da762683446a9bd3f0b24b23d885","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":684,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":684,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac2ae5a2e2a14b878e86529c37b22996"}},"6577f633bf9f4342bf6181b4e27697ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e3f228166a9e46e6bf410c33e36bcc7c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 684/684 [00:00&lt;00:00, 24.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07e5991629db40969b73a7a3eed0f524"}},"b589da762683446a9bd3f0b24b23d885":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac2ae5a2e2a14b878e86529c37b22996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3f228166a9e46e6bf410c33e36bcc7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07e5991629db40969b73a7a3eed0f524":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"3b816077","executionInfo":{"status":"ok","timestamp":1623545481614,"user_tz":240,"elapsed":319,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":["%load_ext autoreload\n","%autoreload 2"],"id":"3b816077","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQcPZpEouvE2","executionInfo":{"status":"ok","timestamp":1623545514362,"user_tz":240,"elapsed":32235,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}},"outputId":"eb7cd85c-3333-46ed-8f48-3a00e19d5f17"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"WQcPZpEouvE2","execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nzgNkHqtuw_A","executionInfo":{"status":"ok","timestamp":1623545514362,"user_tz":240,"elapsed":6,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":["root_path = \"/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2\""],"id":"nzgNkHqtuw_A","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oQq5gk8u1xw","executionInfo":{"status":"ok","timestamp":1623545535056,"user_tz":240,"elapsed":20699,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}},"outputId":"9a5e593f-e82b-438d-81fd-e3a92c87403c"},"source":["!pip install transformers\n","!pip install stop_words\n","!pip install symspellpy\n","!pip install language_detector \n","!pip install cached_property\n","!pip install sentencepiece"],"id":"2oQq5gk8u1xw","execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 13.2MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 42.0MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 68.3MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n","Collecting stop_words\n","  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n","Building wheels for collected packages: stop-words\n","  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for stop-words: filename=stop_words-2018.7.23-cp37-none-any.whl size=32913 sha256=611b00311fe7557fc8ce7cbb3e20ee3a61d01ec014271828af9d093d71017e0a\n","  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n","Successfully built stop-words\n","Installing collected packages: stop-words\n","Successfully installed stop-words-2018.7.23\n","Collecting symspellpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 15.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from symspellpy) (1.19.5)\n","Installing collected packages: symspellpy\n","Successfully installed symspellpy-6.7.0\n","Collecting language_detector\n","  Downloading https://files.pythonhosted.org/packages/5c/0a/fefb61145a386968d2070323b608be6a1eb7508e610c2319daad746c2c33/language-detector-5.0.2.tar.gz\n","Building wheels for collected packages: language-detector\n","  Building wheel for language-detector (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for language-detector: filename=language_detector-5.0.2-cp37-none-any.whl size=7054 sha256=b1729e2fed911153e5e12143209221052ed1ee7b5687324c609d423a7eca5b0b\n","  Stored in directory: /root/.cache/pip/wheels/7d/37/fa/2098a4aa6c0d94d6ddff0d3a79669e12bc4f7baca8a760b3db\n","Successfully built language-detector\n","Installing collected packages: language-detector\n","Successfully installed language-detector-5.0.2\n","Requirement already satisfied: cached_property in /usr/local/lib/python3.7/dist-packages (1.5.2)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 14.5MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eb492ea3","executionInfo":{"status":"ok","timestamp":1623545535057,"user_tz":240,"elapsed":9,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":["import sys\n","sys.path.append(root_path)"],"id":"eb492ea3","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["0621d8d6cf004e8fb3441b21a298a991","73fa7176d55b43d189c9f60de955db00","78b4502a58f54ed8b1cdd997692b187a","6b147f42a11442dd9f95f2e8b02c6fbf","036d201c15cc4dcb849b289184524f11","773a3c034c5541beaaec6b6c86ec78c0","c71b2d518a764324bc12f5caaa99c155","66dc6460fa72474f93d1b8141ff0fe31","4ad341d982094dd08aa260e292e17995","9acb8cdd66144efd84f6fad4ef781844","b436fa0276b94ef9bf5843b5da92049e","a36cfe270c664054b99b695b0088552b","7fd08ad5f2fb44608f1c95d6dfedd36d","acddb2ca9d1c4ba0aa37061ef196aa1a","4108fd104a5f451fa1273e98957f7507","7470da67fe504782b73e021fd2c6e98e"]},"id":"811f4ff7","executionInfo":{"status":"ok","timestamp":1623545557932,"user_tz":240,"elapsed":22883,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}},"outputId":"edb43654-1c71-4af0-e23e-ad3f2568fd27"},"source":["import tensorflow as tf\n","\n","from src.encoders.context_encoder_bert import ContextEncoder\n","\n","from tensorflow.python import keras\n","import toml\n","import json\n","import pandas as pd\n","import numpy as np\n","\n","from src.dataset.albert import AlbertDataset"],"id":"811f4ff7","execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0621d8d6cf004e8fb3441b21a298a991","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ad341d982094dd08aa260e292e17995","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1312669.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"26986a31","executionInfo":{"status":"ok","timestamp":1623545557932,"user_tz":240,"elapsed":4,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":[""],"id":"26986a31","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5a5de02f","executionInfo":{"status":"ok","timestamp":1623545557932,"user_tz":240,"elapsed":3,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":[""],"id":"5a5de02f","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66caca4d"},"source":["## Experiment"],"id":"66caca4d"},{"cell_type":"code","metadata":{"id":"de19ebcd","executionInfo":{"status":"ok","timestamp":1623545559001,"user_tz":240,"elapsed":1071,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":["sys.path.append(root_path)\n","from utils.experiments import get_experiments, save_results"],"id":"de19ebcd","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":326},"id":"f9b44d41","executionInfo":{"status":"ok","timestamp":1623545559834,"user_tz":240,"elapsed":833,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}},"outputId":"6d651ece-c470-4471-e16d-88ae8857f71c"},"source":["# Read local `config.toml` file.\n","config = get_experiments('ALBERT_FINETUNE_SIMPLE')\n","config_df = pd.DataFrame.from_dict(config)\n","config_df"],"id":"f9b44d41","execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bert_type</th>\n","      <th>dataset_type</th>\n","      <th>finetune_bert</th>\n","      <th>pct_data</th>\n","      <th>augment_pct</th>\n","      <th>epochs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>albert</td>\n","      <td>clinical</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>0.1</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>albert</td>\n","      <td>clinical</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>albert</td>\n","      <td>clinical</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>albert</td>\n","      <td>fiction</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>0.1</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>albert</td>\n","      <td>fiction</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>albert</td>\n","      <td>fiction</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>albert</td>\n","      <td>wiki</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>0.1</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>albert</td>\n","      <td>wiki</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>albert</td>\n","      <td>wiki</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  bert_type dataset_type  finetune_bert  pct_data  augment_pct  epochs\n","0    albert     clinical           True         1          0.1     200\n","1    albert     clinical           True         1          0.5     200\n","2    albert     clinical           True         1          1.0     200\n","3    albert      fiction           True         1          0.1     200\n","4    albert      fiction           True         1          0.5     200\n","5    albert      fiction           True         1          1.0     200\n","6    albert         wiki           True         1          0.1     200\n","7    albert         wiki           True         1          0.5     200\n","8    albert         wiki           True         1          1.0     200"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"90091fb0","executionInfo":{"status":"ok","timestamp":1623545560033,"user_tz":240,"elapsed":201,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":["sys.path.append(root_path)\n","config_df.to_csv(f'{root_path}/models/experiment.csv', header=None, index=None, sep=' ', mode='a')"],"id":"90091fb0","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJXQb_X7ymh1","executionInfo":{"status":"ok","timestamp":1623545560034,"user_tz":240,"elapsed":4,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":[""],"id":"iJXQb_X7ymh1","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c4d92118c0e04b58bc67a45eb6fdf785","803abee7e8494d638704197a0651d08e","5139396a570544079a9f9ed498a51e8a","6577f633bf9f4342bf6181b4e27697ee","b589da762683446a9bd3f0b24b23d885","ac2ae5a2e2a14b878e86529c37b22996","e3f228166a9e46e6bf410c33e36bcc7c","07e5991629db40969b73a7a3eed0f524"]},"id":"a8659ace","executionInfo":{"status":"ok","timestamp":1623560660555,"user_tz":240,"elapsed":15100524,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}},"outputId":"8d7048f4-4fa2-4d5c-9782-93b333e4f1ff"},"source":["for experiment in config:\n","    bert_type = experiment['bert_type']\n","    dataset_type = experiment['dataset_type']\n","    finetune_bert = experiment['finetune_bert']\n","    pct_data = 0.25 # experiment['pct_data']\n","    augment_pct = 0.25 # experiment['augment_pct']\n","    epochs = experiment['epochs']\n","    BATCH_SIZE = 64\n","    print(\"params:\", bert_type, dataset_type, finetune_bert, pct_data, augment_pct, epochs)\n","    \n","    # init model\n","    print(\"initializing model...\")\n","    model = ContextEncoder(# final_dropout=0.5,\n","                           dense_neurons=128,\n","                           bert_trainable=finetune_bert,\n","                           bert_type=\"albert-base-v2\")\n","    \n","    # print(\"number of params: \", sum([np.prod(keras.get_value(w).shape) for w in model.trainable_weights]))\n","    \n","    # init dataset\n","    print(\"initializing dataset...\")\n","    dataset = AlbertDataset(dataset_type=dataset_type,\n","                           pct_data=pct_data,\n","                            max_seq_length=64,\n","                           max_segment_length=5,\n","                           augment_pct=augment_pct)\n","    \n","    # process dataset\n","    print(\"processing dataset...\")\n","    sentences, tokenized_sentences, labels = dataset.process()\n","\n","    # get class weight\n","    neg, pos = np.bincount(labels.flatten())\n","    initial_bias = np.log([pos/neg])\n","    \n","    total=len(labels)\n","    weight_for_0 = (1 / neg)*(total)/2.0 \n","    weight_for_1 = (1 / pos)*(total)/2.0\n","\n","    class_weight = {0: weight_for_0, 1: weight_for_1}\n","    print(\"class weight\", class_weight)\n","    \n","    # create checkpoint path\n","    checkpoint_filepath = '{}/models/ALBERT/finetune/simple/{}-{}-{}-pct-{}-aug/checkpoint'.format(\n","                            root_path,\n","                            dataset_type,                    \n","                            len(sentences), \n","                            pct_data,\n","                            augment_pct)\n","    print(checkpoint_filepath)\n","    \n","    # get callbacks ready.\n","    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=checkpoint_filepath,\n","        save_weights_only=True,\n","        monitor='val_accuracy',\n","        save_best_only=False,\n","        mode=\"auto\",\n","        save_freq=\"epoch\")\n","\n","    early_stopping = tf.keras.callbacks.EarlyStopping(\n","        monitor='val_accuracy', \n","        verbose=1,\n","        patience=10,\n","        mode='max',\n","        restore_best_weights=True)\n","\n","    callbacks = [\n","    #     early_stopping,\n","        model_checkpoint_callback\n","    ]\n","    \n","    # compiling model\n","    print(\"compiling the model...\")\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","                  loss=tf.keras.losses.BinaryCrossentropy(),\n","                  metrics=[\n","                      keras.metrics.BinaryAccuracy(name='accuracy')\n","                  ])\n","    \n","    try:\n","        model.load_weights(checkpoint_filepath)\n","        print(\"model loaded.\")\n","    except:\n","        print(\"No checkpoint available.\")\n","    \n","    print(\"starting the training process...\")\n","    history = model.fit(dataset.format_sentences_tri_input(tokenized_sentences), \n","                        tf.convert_to_tensor(labels), \n","                        epochs=epochs,\n","                        validation_split=0.1,\n","                        batch_size=BATCH_SIZE,\n","                        verbose=1, \n","                        # class_weight=class_weight,\n","                        callbacks=callbacks)\n","    \n","    # assigning history to experiment object for saving.\n","    experiment[\"history\"] = history.history\n","    \n","    print(\"saving results...\")\n","    save_results(experiment)\n","    break"],"id":"a8659ace","execution_count":10,"outputs":[{"output_type":"stream","text":["params: albert clinical True 0.25 0.25 200\n","initializing model...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4d92118c0e04b58bc67a45eb6fdf785","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=684.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","initializing dataset...\n","processing dataset...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["class weight {0: 0.636378002528445, 1: 2.333140208574739}\n","/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2/models/ALBERT/finetune/simple/clinical-4027-0.25-pct-0.25-aug/checkpoint\n","compiling the model...\n","No checkpoint available.\n","starting the training process...\n","Epoch 1/200\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","57/57 [==============================] - 118s 1s/step - loss: 0.7710 - accuracy: 0.7409 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 2/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5128 - val_accuracy: 0.7916\n","Epoch 3/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5252 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 4/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5218 - accuracy: 0.7850 - val_loss: 0.5144 - val_accuracy: 0.7916\n","Epoch 5/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5131 - val_accuracy: 0.7916\n","Epoch 6/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5236 - accuracy: 0.7850 - val_loss: 0.5165 - val_accuracy: 0.7916\n","Epoch 7/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5222 - accuracy: 0.7850 - val_loss: 0.5138 - val_accuracy: 0.7916\n","Epoch 8/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5272 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 9/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5241 - accuracy: 0.7850 - val_loss: 0.5186 - val_accuracy: 0.7916\n","Epoch 10/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5241 - accuracy: 0.7850 - val_loss: 0.5185 - val_accuracy: 0.7916\n","Epoch 11/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 12/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5121 - val_accuracy: 0.7916\n","Epoch 13/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5229 - accuracy: 0.7850 - val_loss: 0.5131 - val_accuracy: 0.7916\n","Epoch 14/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5244 - accuracy: 0.7850 - val_loss: 0.5224 - val_accuracy: 0.7916\n","Epoch 15/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5256 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 16/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5247 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 17/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5221 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 18/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5310 - accuracy: 0.7850 - val_loss: 0.5124 - val_accuracy: 0.7916\n","Epoch 19/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5250 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 20/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5214 - accuracy: 0.7850 - val_loss: 0.5145 - val_accuracy: 0.7916\n","Epoch 21/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5262 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 22/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5212 - val_accuracy: 0.7916\n","Epoch 23/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5221 - accuracy: 0.7850 - val_loss: 0.5124 - val_accuracy: 0.7916\n","Epoch 24/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5121 - val_accuracy: 0.7916\n","Epoch 25/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5257 - accuracy: 0.7850 - val_loss: 0.5123 - val_accuracy: 0.7916\n","Epoch 26/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5274 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 27/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5269 - accuracy: 0.7850 - val_loss: 0.5204 - val_accuracy: 0.7916\n","Epoch 28/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5244 - accuracy: 0.7850 - val_loss: 0.5150 - val_accuracy: 0.7916\n","Epoch 29/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5235 - accuracy: 0.7850 - val_loss: 0.5201 - val_accuracy: 0.7916\n","Epoch 30/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5239 - accuracy: 0.7850 - val_loss: 0.5253 - val_accuracy: 0.7916\n","Epoch 31/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5401 - accuracy: 0.7850 - val_loss: 0.5298 - val_accuracy: 0.7916\n","Epoch 32/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5285 - accuracy: 0.7850 - val_loss: 0.5351 - val_accuracy: 0.7916\n","Epoch 33/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5262 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 34/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5249 - accuracy: 0.7850 - val_loss: 0.5121 - val_accuracy: 0.7916\n","Epoch 35/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5248 - accuracy: 0.7850 - val_loss: 0.5123 - val_accuracy: 0.7916\n","Epoch 36/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5292 - accuracy: 0.7850 - val_loss: 0.5192 - val_accuracy: 0.7916\n","Epoch 37/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5234 - accuracy: 0.7850 - val_loss: 0.5124 - val_accuracy: 0.7916\n","Epoch 38/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5252 - accuracy: 0.7850 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 39/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 40/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5246 - accuracy: 0.7850 - val_loss: 0.5127 - val_accuracy: 0.7916\n","Epoch 41/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5264 - accuracy: 0.7850 - val_loss: 0.5131 - val_accuracy: 0.7916\n","Epoch 42/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5229 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 43/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5219 - accuracy: 0.7850 - val_loss: 0.5125 - val_accuracy: 0.7916\n","Epoch 44/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5222 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 45/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5213 - accuracy: 0.7850 - val_loss: 0.5140 - val_accuracy: 0.7916\n","Epoch 46/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5275 - accuracy: 0.7850 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 47/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5252 - accuracy: 0.7850 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 48/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5234 - accuracy: 0.7850 - val_loss: 0.5141 - val_accuracy: 0.7916\n","Epoch 49/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5254 - accuracy: 0.7850 - val_loss: 0.5168 - val_accuracy: 0.7916\n","Epoch 50/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5232 - accuracy: 0.7850 - val_loss: 0.5172 - val_accuracy: 0.7916\n","Epoch 51/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5237 - accuracy: 0.7850 - val_loss: 0.5129 - val_accuracy: 0.7916\n","Epoch 52/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5258 - accuracy: 0.7850 - val_loss: 0.5165 - val_accuracy: 0.7916\n","Epoch 53/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5227 - accuracy: 0.7850 - val_loss: 0.5174 - val_accuracy: 0.7916\n","Epoch 54/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5227 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 55/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 56/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5250 - accuracy: 0.7850 - val_loss: 0.5266 - val_accuracy: 0.7916\n","Epoch 57/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5241 - accuracy: 0.7850 - val_loss: 0.5137 - val_accuracy: 0.7916\n","Epoch 58/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5232 - accuracy: 0.7850 - val_loss: 0.5160 - val_accuracy: 0.7916\n","Epoch 59/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5268 - accuracy: 0.7850 - val_loss: 0.5212 - val_accuracy: 0.7916\n","Epoch 60/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5240 - accuracy: 0.7850 - val_loss: 0.5197 - val_accuracy: 0.7916\n","Epoch 61/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5236 - accuracy: 0.7850 - val_loss: 0.5169 - val_accuracy: 0.7916\n","Epoch 62/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5234 - accuracy: 0.7850 - val_loss: 0.5141 - val_accuracy: 0.7916\n","Epoch 63/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5259 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 64/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5232 - accuracy: 0.7850 - val_loss: 0.5128 - val_accuracy: 0.7916\n","Epoch 65/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5212 - accuracy: 0.7850 - val_loss: 0.5121 - val_accuracy: 0.7916\n","Epoch 66/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5224 - accuracy: 0.7850 - val_loss: 0.5188 - val_accuracy: 0.7916\n","Epoch 67/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5236 - accuracy: 0.7850 - val_loss: 0.5124 - val_accuracy: 0.7916\n","Epoch 68/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5232 - accuracy: 0.7850 - val_loss: 0.5223 - val_accuracy: 0.7916\n","Epoch 69/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5249 - accuracy: 0.7850 - val_loss: 0.5324 - val_accuracy: 0.7916\n","Epoch 70/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5244 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 71/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5229 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 72/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5271 - accuracy: 0.7850 - val_loss: 0.5270 - val_accuracy: 0.7916\n","Epoch 73/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5253 - accuracy: 0.7850 - val_loss: 0.5488 - val_accuracy: 0.7916\n","Epoch 74/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5256 - accuracy: 0.7850 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 75/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5243 - accuracy: 0.7850 - val_loss: 0.5242 - val_accuracy: 0.7916\n","Epoch 76/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5291 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 77/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5281 - accuracy: 0.7850 - val_loss: 0.5261 - val_accuracy: 0.7916\n","Epoch 78/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5249 - accuracy: 0.7850 - val_loss: 0.5126 - val_accuracy: 0.7916\n","Epoch 79/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5253 - accuracy: 0.7850 - val_loss: 0.5185 - val_accuracy: 0.7916\n","Epoch 80/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5237 - accuracy: 0.7850 - val_loss: 0.5160 - val_accuracy: 0.7916\n","Epoch 81/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5218 - accuracy: 0.7850 - val_loss: 0.5188 - val_accuracy: 0.7916\n","Epoch 82/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5239 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 83/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5251 - accuracy: 0.7850 - val_loss: 0.5168 - val_accuracy: 0.7916\n","Epoch 84/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5230 - accuracy: 0.7850 - val_loss: 0.5142 - val_accuracy: 0.7916\n","Epoch 85/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5239 - accuracy: 0.7850 - val_loss: 0.5201 - val_accuracy: 0.7916\n","Epoch 86/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5282 - accuracy: 0.7850 - val_loss: 0.5141 - val_accuracy: 0.7916\n","Epoch 87/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5227 - accuracy: 0.7850 - val_loss: 0.5181 - val_accuracy: 0.7916\n","Epoch 88/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5233 - accuracy: 0.7850 - val_loss: 0.5125 - val_accuracy: 0.7916\n","Epoch 89/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5263 - accuracy: 0.7850 - val_loss: 0.5420 - val_accuracy: 0.7916\n","Epoch 90/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5327 - val_accuracy: 0.7916\n","Epoch 91/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5254 - accuracy: 0.7850 - val_loss: 0.5123 - val_accuracy: 0.7916\n","Epoch 92/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5261 - accuracy: 0.7850 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 93/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5228 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 94/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5231 - accuracy: 0.7850 - val_loss: 0.5144 - val_accuracy: 0.7916\n","Epoch 95/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 96/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5218 - accuracy: 0.7850 - val_loss: 0.5175 - val_accuracy: 0.7916\n","Epoch 97/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5280 - accuracy: 0.7850 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 98/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5224 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 99/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5124 - val_accuracy: 0.7916\n","Epoch 100/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5269 - accuracy: 0.7850 - val_loss: 0.5184 - val_accuracy: 0.7916\n","Epoch 101/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5298 - accuracy: 0.7850 - val_loss: 0.5167 - val_accuracy: 0.7916\n","Epoch 102/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5237 - accuracy: 0.7850 - val_loss: 0.5136 - val_accuracy: 0.7916\n","Epoch 103/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5244 - accuracy: 0.7850 - val_loss: 0.5140 - val_accuracy: 0.7916\n","Epoch 104/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5319 - accuracy: 0.7850 - val_loss: 0.5148 - val_accuracy: 0.7916\n","Epoch 105/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5233 - accuracy: 0.7850 - val_loss: 0.5146 - val_accuracy: 0.7916\n","Epoch 106/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5231 - accuracy: 0.7850 - val_loss: 0.5247 - val_accuracy: 0.7916\n","Epoch 107/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5257 - accuracy: 0.7850 - val_loss: 0.5153 - val_accuracy: 0.7916\n","Epoch 108/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5255 - accuracy: 0.7850 - val_loss: 0.5197 - val_accuracy: 0.7916\n","Epoch 109/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5236 - accuracy: 0.7850 - val_loss: 0.5141 - val_accuracy: 0.7916\n","Epoch 110/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5257 - accuracy: 0.7850 - val_loss: 0.5128 - val_accuracy: 0.7916\n","Epoch 111/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5250 - accuracy: 0.7850 - val_loss: 0.5123 - val_accuracy: 0.7916\n","Epoch 112/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5246 - accuracy: 0.7850 - val_loss: 0.5139 - val_accuracy: 0.7916\n","Epoch 113/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5230 - accuracy: 0.7850 - val_loss: 0.5138 - val_accuracy: 0.7916\n","Epoch 114/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5248 - accuracy: 0.7850 - val_loss: 0.5155 - val_accuracy: 0.7916\n","Epoch 115/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5234 - accuracy: 0.7850 - val_loss: 0.5194 - val_accuracy: 0.7916\n","Epoch 116/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5263 - accuracy: 0.7850 - val_loss: 0.5131 - val_accuracy: 0.7916\n","Epoch 117/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5304 - accuracy: 0.7850 - val_loss: 0.5130 - val_accuracy: 0.7916\n","Epoch 118/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5292 - accuracy: 0.7850 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 119/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 120/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5245 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 121/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5230 - accuracy: 0.7850 - val_loss: 0.5129 - val_accuracy: 0.7916\n","Epoch 122/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5233 - accuracy: 0.7850 - val_loss: 0.5142 - val_accuracy: 0.7916\n","Epoch 123/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5130 - val_accuracy: 0.7916\n","Epoch 124/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5290 - val_accuracy: 0.7916\n","Epoch 125/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5255 - accuracy: 0.7850 - val_loss: 0.5336 - val_accuracy: 0.7916\n","Epoch 126/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5301 - accuracy: 0.7850 - val_loss: 0.5136 - val_accuracy: 0.7916\n","Epoch 127/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5315 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 128/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5229 - accuracy: 0.7850 - val_loss: 0.5121 - val_accuracy: 0.7916\n","Epoch 129/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5277 - accuracy: 0.7850 - val_loss: 0.5157 - val_accuracy: 0.7916\n","Epoch 130/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5129 - val_accuracy: 0.7916\n","Epoch 131/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5228 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 132/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5245 - accuracy: 0.7850 - val_loss: 0.5158 - val_accuracy: 0.7916\n","Epoch 133/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5251 - accuracy: 0.7850 - val_loss: 0.5155 - val_accuracy: 0.7916\n","Epoch 134/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5243 - accuracy: 0.7850 - val_loss: 0.5182 - val_accuracy: 0.7916\n","Epoch 135/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5162 - val_accuracy: 0.7916\n","Epoch 136/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5232 - accuracy: 0.7850 - val_loss: 0.5162 - val_accuracy: 0.7916\n","Epoch 137/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5162 - val_accuracy: 0.7916\n","Epoch 138/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5228 - accuracy: 0.7850 - val_loss: 0.5150 - val_accuracy: 0.7916\n","Epoch 139/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5232 - accuracy: 0.7850 - val_loss: 0.5124 - val_accuracy: 0.7916\n","Epoch 140/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5233 - accuracy: 0.7850 - val_loss: 0.5174 - val_accuracy: 0.7916\n","Epoch 141/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5275 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 142/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5152 - val_accuracy: 0.7916\n","Epoch 143/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5224 - accuracy: 0.7850 - val_loss: 0.5178 - val_accuracy: 0.7916\n","Epoch 144/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5292 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 145/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5212 - accuracy: 0.7850 - val_loss: 0.5180 - val_accuracy: 0.7916\n","Epoch 146/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5269 - accuracy: 0.7850 - val_loss: 0.5142 - val_accuracy: 0.7916\n","Epoch 147/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5234 - accuracy: 0.7850 - val_loss: 0.5126 - val_accuracy: 0.7916\n","Epoch 148/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5261 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 149/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5277 - accuracy: 0.7850 - val_loss: 0.5390 - val_accuracy: 0.7916\n","Epoch 150/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5263 - accuracy: 0.7850 - val_loss: 0.5139 - val_accuracy: 0.7916\n","Epoch 151/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5250 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 152/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5247 - accuracy: 0.7850 - val_loss: 0.5132 - val_accuracy: 0.7916\n","Epoch 153/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5224 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 154/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5234 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 155/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5293 - accuracy: 0.7850 - val_loss: 0.5289 - val_accuracy: 0.7916\n","Epoch 156/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5159 - val_accuracy: 0.7916\n","Epoch 157/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5128 - val_accuracy: 0.7916\n","Epoch 158/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5228 - accuracy: 0.7850 - val_loss: 0.5158 - val_accuracy: 0.7916\n","Epoch 159/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5286 - accuracy: 0.7850 - val_loss: 0.5133 - val_accuracy: 0.7916\n","Epoch 160/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5219 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 161/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5272 - accuracy: 0.7850 - val_loss: 0.5121 - val_accuracy: 0.7916\n","Epoch 162/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5260 - accuracy: 0.7850 - val_loss: 0.5129 - val_accuracy: 0.7916\n","Epoch 163/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5261 - val_accuracy: 0.7916\n","Epoch 164/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5249 - val_accuracy: 0.7916\n","Epoch 165/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5248 - accuracy: 0.7850 - val_loss: 0.5286 - val_accuracy: 0.7916\n","Epoch 166/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5270 - accuracy: 0.7850 - val_loss: 0.5122 - val_accuracy: 0.7916\n","Epoch 167/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5220 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 168/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5254 - accuracy: 0.7850 - val_loss: 0.5123 - val_accuracy: 0.7916\n","Epoch 169/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5245 - accuracy: 0.7850 - val_loss: 0.5171 - val_accuracy: 0.7916\n","Epoch 170/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5231 - accuracy: 0.7850 - val_loss: 0.5150 - val_accuracy: 0.7916\n","Epoch 171/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5187 - val_accuracy: 0.7916\n","Epoch 172/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5250 - accuracy: 0.7850 - val_loss: 0.5129 - val_accuracy: 0.7916\n","Epoch 173/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5232 - accuracy: 0.7850 - val_loss: 0.5241 - val_accuracy: 0.7916\n","Epoch 174/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5223 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 175/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5217 - val_accuracy: 0.7916\n","Epoch 176/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5242 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 177/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5233 - accuracy: 0.7850 - val_loss: 0.5131 - val_accuracy: 0.7916\n","Epoch 178/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5257 - accuracy: 0.7850 - val_loss: 0.5406 - val_accuracy: 0.7916\n","Epoch 179/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5285 - accuracy: 0.7850 - val_loss: 0.5158 - val_accuracy: 0.7916\n","Epoch 180/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5226 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 181/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5232 - accuracy: 0.7850 - val_loss: 0.5121 - val_accuracy: 0.7916\n","Epoch 182/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5244 - accuracy: 0.7850 - val_loss: 0.5188 - val_accuracy: 0.7916\n","Epoch 183/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5259 - accuracy: 0.7850 - val_loss: 0.5123 - val_accuracy: 0.7916\n","Epoch 184/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5238 - accuracy: 0.7850 - val_loss: 0.5322 - val_accuracy: 0.7916\n","Epoch 185/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5270 - accuracy: 0.7850 - val_loss: 0.5141 - val_accuracy: 0.7916\n","Epoch 186/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5333 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 187/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5270 - accuracy: 0.7850 - val_loss: 0.5403 - val_accuracy: 0.7916\n","Epoch 188/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5262 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 189/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5230 - accuracy: 0.7850 - val_loss: 0.5138 - val_accuracy: 0.7916\n","Epoch 190/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5251 - accuracy: 0.7850 - val_loss: 0.5246 - val_accuracy: 0.7916\n","Epoch 191/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5251 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 192/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5263 - accuracy: 0.7850 - val_loss: 0.5216 - val_accuracy: 0.7916\n","Epoch 193/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5275 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 194/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5238 - accuracy: 0.7850 - val_loss: 0.5195 - val_accuracy: 0.7916\n","Epoch 195/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5264 - accuracy: 0.7850 - val_loss: 0.5159 - val_accuracy: 0.7916\n","Epoch 196/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5257 - accuracy: 0.7850 - val_loss: 0.5130 - val_accuracy: 0.7916\n","Epoch 197/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5241 - accuracy: 0.7850 - val_loss: 0.5119 - val_accuracy: 0.7916\n","Epoch 198/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5230 - accuracy: 0.7850 - val_loss: 0.5120 - val_accuracy: 0.7916\n","Epoch 199/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5255 - accuracy: 0.7850 - val_loss: 0.5145 - val_accuracy: 0.7916\n","Epoch 200/200\n","57/57 [==============================] - 75s 1s/step - loss: 0.5233 - accuracy: 0.7850 - val_loss: 0.5230 - val_accuracy: 0.7916\n","saving results...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fyRFxeEbxcmw","executionInfo":{"status":"ok","timestamp":1623560660557,"user_tz":240,"elapsed":11,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"}}},"source":[""],"id":"fyRFxeEbxcmw","execution_count":10,"outputs":[]}]}