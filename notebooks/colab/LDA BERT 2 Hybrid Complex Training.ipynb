{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"LDA BERT 2 Hybrid Complex Training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3b816077","executionInfo":{"status":"ok","timestamp":1634179420319,"user_tz":240,"elapsed":14,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}}},"source":["%load_ext autoreload\n","%autoreload 2"],"id":"3b816077","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQcPZpEouvE2","executionInfo":{"status":"ok","timestamp":1634179447463,"user_tz":240,"elapsed":27155,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}},"outputId":"0455d7a2-dc5d-40ce-8e85-a3cc760ccadd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"WQcPZpEouvE2","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUECyENeltWJ","executionInfo":{"status":"ok","timestamp":1634179484468,"user_tz":240,"elapsed":37010,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}},"outputId":"6eaf1ecc-211e-498d-e58a-a37dc625faad"},"source":["!pip install transformers==4.3.3\n","!pip install stop_words\n","!pip install symspellpy\n","!pip install language_detector \n","!pip install cached_property\n","!pip install sentencepiece\n","!pip install config\n","!pip install umap\n","!pip install sentence-transformers==0.4.1\n","!pip install nltk\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"],"id":"vUECyENeltWJ","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.3.3\n","  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (21.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (3.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 62.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (4.8.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 73.5 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.3.3\n","Collecting stop_words\n","  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n","Building wheels for collected packages: stop-words\n","  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32912 sha256=8167f92f865a5892feb133500dc959ea923ac6264591e283e851e489510c8afa\n","  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n","Successfully built stop-words\n","Installing collected packages: stop-words\n","Successfully installed stop-words-2018.7.23\n","Collecting symspellpy\n","  Downloading symspellpy-6.7.0-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from symspellpy) (1.19.5)\n","Installing collected packages: symspellpy\n","Successfully installed symspellpy-6.7.0\n","Collecting language_detector\n","  Downloading language-detector-5.0.2.tar.gz (6.6 kB)\n","Building wheels for collected packages: language-detector\n","  Building wheel for language-detector (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for language-detector: filename=language_detector-5.0.2-py3-none-any.whl size=7053 sha256=12dd0751490ac456dae3c6924be5fdc92446846a0703cb60c0b0597694806889\n","  Stored in directory: /root/.cache/pip/wheels/12/40/73/a0765d65e793332b79dfe6c34c713e7c0066ea785191b3f50a\n","Successfully built language-detector\n","Installing collected packages: language-detector\n","Successfully installed language-detector-5.0.2\n","Requirement already satisfied: cached_property in /usr/local/lib/python3.7/dist-packages (1.5.2)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 4.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting config\n","  Downloading config-0.5.1-py2.py3-none-any.whl (20 kB)\n","Installing collected packages: config\n","Successfully installed config-0.5.1\n","Collecting umap\n","  Downloading umap-0.1.1.tar.gz (3.2 kB)\n","Building wheels for collected packages: umap\n","  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3564 sha256=6563177cbb3054d47d6d692dc23c54ad7772a0c544d065c631ec0d144a6a14d4\n","  Stored in directory: /root/.cache/pip/wheels/65/55/85/945cfb3d67373767e4dc3e9629300a926edde52633df4f0efe\n","Successfully built umap\n","Installing collected packages: umap\n","Successfully installed umap-0.1.1\n","Collecting sentence-transformers==0.4.1\n","  Downloading sentence-transformers-0.4.1.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.4.1) (4.3.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.4.1) (4.62.3)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.4.1) (1.9.0+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.4.1) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.4.1) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.4.1) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.4.1) (3.2.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.4.1) (0.1.96)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers==0.4.1) (3.7.4.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (21.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (0.0.46)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (3.3.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (0.10.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (4.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2.23.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (3.6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers==0.4.1) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers==0.4.1) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1-py3-none-any.whl size=103051 sha256=ecf88efa55edd369ee64871274827f395ecf04938bd9b5ee10863faf3508865e\n","  Stored in directory: /root/.cache/pip/wheels/ed/2b/00/349b245f5256ba7a5d874bcb0f1f2dfc8b4b963d80b38626ac\n","Successfully built sentence-transformers\n","Installing collected packages: sentence-transformers\n","Successfully installed sentence-transformers-0.4.1\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7yHUDTQ13BL","executionInfo":{"status":"ok","timestamp":1634179499186,"user_tz":240,"elapsed":14733,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}},"outputId":"88b1c584-00d0-4111-b502-4de7319fa852"},"source":["import tensorflow, sentence_transformers, transformers\n","tensorflow.__version__, sentence_transformers.__version__, transformers.__version__"],"id":"J7yHUDTQ13BL","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('2.6.0', '0.4.1', '4.3.3')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"nzgNkHqtuw_A","executionInfo":{"status":"ok","timestamp":1634179499187,"user_tz":240,"elapsed":16,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}}},"source":["root_path = \"/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2\"\n","import sys, os\n","import config\n","\n","config.root_path = os.path.abspath(root_path)\n","sys.path.insert(0, config.root_path)"],"id":"nzgNkHqtuw_A","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"id":"811f4ff7","executionInfo":{"status":"ok","timestamp":1634179541008,"user_tz":240,"elapsed":41836,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}},"outputId":"58cddefc-cddd-4787-8157-cf3fe8a14c47"},"source":["import tensorflow as tf\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","from src.encoders.context_encoder_ldabert_2 import ContextEncoderComplex\n","from src.dataset.ldabert_2 import LDABERT2Dataset\n","\n","from tensorflow.python import keras\n","import toml\n","import json\n","import pandas as pd\n","import numpy as np\n","from utils.experiments import get_experiments_json, get_experiments, save_results"],"id":"811f4ff7","execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"baf0506893034193b013f2c73e04e31b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/630 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fdf795eb00d34f0ea29a8ca02880e12c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed026444fef3468c93d865e12c2e1d7b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f09d1848a574a0887943bacd52dd978","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18c02de030474d94a882cd95b7ad10ed","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a113fcb8ed9144a1a9264d5dbbe69455","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/409 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"26986a31","executionInfo":{"status":"ok","timestamp":1634179541928,"user_tz":240,"elapsed":931,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}}},"source":[""],"id":"26986a31","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5a5de02f","executionInfo":{"status":"ok","timestamp":1634179541929,"user_tz":240,"elapsed":3,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}}},"source":[""],"id":"5a5de02f","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66caca4d"},"source":["## Experiment"],"id":"66caca4d"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"gTJTmy-X1gyN","executionInfo":{"status":"ok","timestamp":1634179542175,"user_tz":240,"elapsed":249,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}},"outputId":"8d01c71f-2742-418d-df16-efeaf770becb"},"source":["experiments_config = get_experiments_json('ldabert2_complex_finetune_test')\n","experiments_config_df = pd.DataFrame.from_dict(experiments_config)\n","experiments_config_df"],"id":"gTJTmy-X1gyN","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bert_type</th>\n","      <th>dataset_type</th>\n","      <th>final_dropout</th>\n","      <th>dense_neurons</th>\n","      <th>max_sentence_length</th>\n","      <th>lstm_size</th>\n","      <th>lstm_dropout_percentage</th>\n","      <th>cnn_filters</th>\n","      <th>cnn_kernel_size</th>\n","      <th>pool_size</th>\n","      <th>gamma</th>\n","      <th>pct_data</th>\n","      <th>augment_pct</th>\n","      <th>bert_trainable</th>\n","      <th>epochs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ldabert</td>\n","      <td>clinical</td>\n","      <td>0.25</td>\n","      <td>256</td>\n","      <td>128</td>\n","      <td>256</td>\n","      <td>0.25</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ldabert</td>\n","      <td>wiki</td>\n","      <td>0.25</td>\n","      <td>256</td>\n","      <td>128</td>\n","      <td>256</td>\n","      <td>0.25</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ldabert</td>\n","      <td>fiction</td>\n","      <td>0.25</td>\n","      <td>256</td>\n","      <td>128</td>\n","      <td>256</td>\n","      <td>0.25</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  bert_type dataset_type  final_dropout  ...  augment_pct  bert_trainable  epochs\n","0   ldabert     clinical           0.25  ...            1            True     200\n","1   ldabert         wiki           0.25  ...            1            True     200\n","2   ldabert      fiction           0.25  ...            1            True     200\n","\n","[3 rows x 15 columns]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"p-JZ0fAd1oBO","executionInfo":{"status":"ok","timestamp":1634179542970,"user_tz":240,"elapsed":800,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}}},"source":["experiments_config_df.to_csv(r'../models/experiment.csv', header=None, index=None, sep=' ', mode='a')"],"id":"p-JZ0fAd1oBO","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtQh12191ome","executionInfo":{"status":"ok","timestamp":1634179542971,"user_tz":240,"elapsed":6,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}}},"source":["def get_random_hash(k):\n","  import random, string\n","  x = ''.join(random.choices(string.ascii_letters + string.digits, k=k))\n","  return x"],"id":"rtQh12191ome","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJXQb_X7ymh1","executionInfo":{"status":"ok","timestamp":1634179542971,"user_tz":240,"elapsed":4,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}}},"source":[""],"id":"iJXQb_X7ymh1","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8659ace","executionInfo":{"status":"ok","timestamp":1634261401750,"user_tz":240,"elapsed":67635401,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5Qq3Xanu7RiUeJRvmXgpWd9D3rQSG3F2_2lZizZg=s64","userId":"07292138418067546452"}},"outputId":"8847f5ec-8d89-4806-e0eb-1d0ea2a305f2"},"source":["# just do clinical for now\n","for experiment in experiments_config[:1]:\n","    dataset_type = experiment['dataset_type']\n","    final_dropout = experiment['final_dropout']\n","    dense_neurons = experiment['dense_neurons']\n","    lstm_size = experiment['lstm_size']\n","    lstm_dropout_percentage = experiment['lstm_dropout_percentage']\n","    cnn_filters = experiment['cnn_filters']\n","    cnn_kernel_size = experiment['cnn_kernel_size']\n","    pool_size = experiment['pool_size']\n","    \n","    pct_data = experiment['pct_data']\n","    augment_pct = experiment['augment_pct']\n","    gamma = experiment['gamma']\n","    max_sentence_length = experiment['max_sentence_length']\n","    bert_trainable = experiment['bert_trainable']\n","    finetuning_epochs = 5 # finetune the system for 5 epochs before training with the frozen finetuned BERT weights\n","    epochs = experiment['epochs']\n","    BATCH_SIZE = 8\n","    print(\"params:\", experiment)\n","    random_hash = get_random_hash(5)\n","    experiment['epochs'] = epochs\n","\n","    for step in [\"finetune\",\"frozen\"]:\n","    # for step in [\"frozen\"]:\n","    \n","      # init model\n","      print(\"initializing model...\")\n","      model = ContextEncoderComplex(final_dropout=final_dropout,\n","                              dense_neurons=dense_neurons,\n","                                    lstm_size=lstm_size,\n","                              lstm_dropout_percentage=lstm_dropout_percentage,\n","                              cnn_filters=cnn_filters,\n","                              cnn_kernel_size=cnn_kernel_size,\n","                              pool_size=pool_size,\n","                            gamma=gamma,\n","                            max_sentence_length=max_sentence_length,\n","                            bert_trainable=True if step == \"finetune\" else False)\n","      \n","      # print(\"number of params: \", sum([np.prod(keras.get_value(w).shape) for w in model.trainable_weights]))\n","      \n","      # init dataset\n","      print(\"initializing dataset...\")\n","      dataset = LDABERT2Dataset(dataset_type=dataset_type,\n","                              pct_data=pct_data,\n","                            max_seq_length=max_sentence_length,\n","                              max_segment_length=5,\n","                              augment_pct=augment_pct,\n","                              split=\"train\",\n","                        artificial_segments=True)\n","      \n","      # process dataset\n","      print(\"processing dataset...\")\n","      sentences, tokenized_sentences, labels = dataset.process()\n","\n","      vectors_filename = '{}_{}_artificial-segments-{}.pkl'.format(dataset.pct_data, dataset.augment_pct, dataset.artificial_segments)\n","\n","      saved_vectors, saved_labels, saved_sentences, saved_tokenized_sentences = dataset.get_saved_vectors(\"train\", dataset.dataset_type, vectors_filename)\n","\n","      if len(saved_vectors) == 0:\n","          saved_vectors, saved_labels, saved_sentences, saved_tokenized_sentences = dataset.create_vectors(\"train\", dataset.dataset_type, vectors_filename)\n","\n","      left_input, mid_input, right_input = dataset.format_sentences_tri_input_plus(saved_tokenized_sentences)\n","      lda_left_input, lda_mid_input, lda_right_input = dataset.format_sentences_tri_input(saved_vectors)\n","\n","      # get class weight\n","      neg, pos = np.bincount(labels.flatten())\n","      initial_bias = np.log([pos/neg])\n","      \n","      total=len(labels)\n","      weight_for_0 = (1 / neg)*(total)/2.0 \n","      weight_for_1 = (1 / pos)*(total)/2.0\n","\n","      class_weight = {0: weight_for_0, 1: weight_for_1}\n","      print(\"class weight\", class_weight)\n","      \n","      # create checkpoint path\n","      checkpoint_filepath = '{}/models/LDABERT2/hybrid/{}-{}-{}-pct-{}-aug_{}/checkpoint'.format(\n","                              config.root_path,\n","                              dataset.dataset_type,                    \n","                              len(saved_sentences), \n","                              dataset.pct_data,\n","                              dataset.augment_pct,\n","                              random_hash)\n","      \n","      # continue training\n","      if step == \"frozen\":\n","        # random_hash = 'WLZ0q'\n","        checkpoint_filepath = '{}/models/LDABERT2/hybrid/{}-{}-{}-pct-{}-aug_{}/checkpoint'.format(\n","                              config.root_path,\n","                              dataset.dataset_type,                    \n","                              len(saved_sentences), \n","                              dataset.pct_data,\n","                              dataset.augment_pct,\n","                              random_hash)\n","      \n","      print(checkpoint_filepath)\n","      \n","      # get callbacks ready.\n","      model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","          filepath=checkpoint_filepath,\n","          save_weights_only=False,\n","          monitor='val_accuracy',\n","          save_best_only=True,\n","          mode=\"auto\",\n","          save_freq=\"epoch\")\n","\n","      early_stopping = tf.keras.callbacks.EarlyStopping(\n","          monitor='val_accuracy', \n","          verbose=1,\n","          patience=10,\n","          mode='max',\n","          restore_best_weights=True)\n","      \n","      log_path = '{}/models/LDABERT2/hybrid/{}-{}-{}-pct-{}-aug_{}/checkpoint/training.log'.format(\n","                              config.root_path,\n","                              dataset.dataset_type,                    \n","                              len(saved_sentences), \n","                              dataset.pct_data,\n","                              dataset.augment_pct,\n","                              random_hash)\n","\n","      csv_logger = tf.keras.callbacks.CSVLogger(log_path, separator=\",\", append=False)\n","\n","      callbacks = [\n","      #     early_stopping,\n","          model_checkpoint_callback,\n","          csv_logger\n","      ]\n","      \n","      # compiling model\n","      print(\"compiling the model...\")\n","      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","                    loss=tf.keras.losses.BinaryCrossentropy(),\n","                    metrics=[\n","                        keras.metrics.BinaryAccuracy(name='accuracy')\n","                    ])\n","      \n","      try:\n","          model.load_weights(checkpoint_filepath)\n","          print(\"model loaded.\")\n","      except:\n","          print(\"No checkpoint available.\")\n","      \n","      print(\"starting the training process...\")\n","      # remove warnings\n","      tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","      history = model.fit([\n","                              left_input, mid_input, right_input, \n","                              lda_left_input, lda_mid_input, lda_right_input\n","                          ], \n","                          tf.convert_to_tensor(saved_labels), \n","                          epochs=finetuning_epochs if step == \"finetune\" else epochs,\n","                          validation_split=0.25,\n","                          batch_size=BATCH_SIZE,\n","                          verbose=1, \n","                          class_weight=class_weight,\n","                          callbacks=callbacks)\n","\n","      # assigning history to experiment object for saving.\n","      experiment[\"history\"] = history.history\n","      experiment[\"hash\"] = random_hash\n","      \n","      print(\"saving results...\")\n","      save_results(experiment)"],"id":"a8659ace","execution_count":12,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["params: {'bert_type': 'ldabert', 'dataset_type': 'clinical', 'final_dropout': 0.25, 'dense_neurons': 256, 'max_sentence_length': 128, 'lstm_size': 256, 'lstm_dropout_percentage': 0.25, 'cnn_filters': 8, 'cnn_kernel_size': 3, 'pool_size': 2, 'gamma': 15, 'pct_data': 1, 'augment_pct': 1, 'bert_trainable': True, 'epochs': 200}\n","initializing model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["initializing dataset...\n","processing dataset...\n","artificial segments True\n","artificial segments True\n","class weight {0: 0.5456152758132956, 1: 5.98062015503876}\n","/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2/models/LDABERT2/hybrid/clinical-38575-1-pct-1-aug_NIS3D/checkpoint\n","compiling the model...\n","No checkpoint available.\n","starting the training process...\n","Epoch 1/5\n","3617/3617 [==============================] - 938s 250ms/step - loss: 0.5950 - accuracy: 0.7406 - val_loss: 0.5657 - val_accuracy: 0.7503\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/5\n","3617/3617 [==============================] - 898s 248ms/step - loss: 0.5784 - accuracy: 0.7595 - val_loss: 0.6015 - val_accuracy: 0.7626\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 3/5\n","3617/3617 [==============================] - 899s 248ms/step - loss: 0.5742 - accuracy: 0.7631 - val_loss: 0.5725 - val_accuracy: 0.7644\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 4/5\n","3617/3617 [==============================] - 898s 248ms/step - loss: 0.5770 - accuracy: 0.7658 - val_loss: 0.6022 - val_accuracy: 0.7632\n","Epoch 5/5\n","3617/3617 [==============================] - 899s 249ms/step - loss: 0.5778 - accuracy: 0.7620 - val_loss: 0.5778 - val_accuracy: 0.7633\n","saving results...\n","initializing model...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["initializing dataset...\n","processing dataset...\n","artificial segments True\n","artificial segments True\n","class weight {0: 0.5456152758132956, 1: 5.98062015503876}\n","/content/drive/MyDrive/SCHOOL/PhD/Code/context-encoder-v2/models/LDABERT2/hybrid/clinical-38575-1-pct-1-aug_NIS3D/checkpoint\n","compiling the model...\n","model loaded.\n","starting the training process...\n","Epoch 1/200\n","3617/3617 [==============================] - 415s 107ms/step - loss: 0.5792 - accuracy: 0.7927 - val_loss: 0.6282 - val_accuracy: 0.7612\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5756 - accuracy: 0.7563 - val_loss: 0.6120 - val_accuracy: 0.7557\n","Epoch 3/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5754 - accuracy: 0.7556 - val_loss: 0.5407 - val_accuracy: 0.7587\n","Epoch 4/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5711 - accuracy: 0.7625 - val_loss: 0.5458 - val_accuracy: 0.7640\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 5/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5700 - accuracy: 0.7645 - val_loss: 0.5637 - val_accuracy: 0.7653\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 6/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5694 - accuracy: 0.7668 - val_loss: 0.6117 - val_accuracy: 0.7649\n","Epoch 7/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5624 - accuracy: 0.7644 - val_loss: 0.4545 - val_accuracy: 0.7657\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 8/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5618 - accuracy: 0.7669 - val_loss: 0.5277 - val_accuracy: 0.7678\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 9/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5578 - accuracy: 0.7683 - val_loss: 0.5941 - val_accuracy: 0.7675\n","Epoch 10/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5579 - accuracy: 0.7670 - val_loss: 0.4594 - val_accuracy: 0.7681\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 11/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5584 - accuracy: 0.7692 - val_loss: 0.4816 - val_accuracy: 0.7698\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 12/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5535 - accuracy: 0.7706 - val_loss: 0.5074 - val_accuracy: 0.7709\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 13/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5520 - accuracy: 0.7712 - val_loss: 0.5075 - val_accuracy: 0.7713\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 14/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5547 - accuracy: 0.7719 - val_loss: 0.4846 - val_accuracy: 0.7720\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 15/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5514 - accuracy: 0.7724 - val_loss: 0.4961 - val_accuracy: 0.7727\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 16/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5511 - accuracy: 0.7727 - val_loss: 0.5487 - val_accuracy: 0.7727\n","Epoch 17/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5531 - accuracy: 0.7725 - val_loss: 0.5294 - val_accuracy: 0.7725\n","Epoch 18/200\n","3617/3617 [==============================] - 384s 106ms/step - loss: 0.5517 - accuracy: 0.7725 - val_loss: 0.4546 - val_accuracy: 0.7730\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 19/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5475 - accuracy: 0.7733 - val_loss: 0.5542 - val_accuracy: 0.7732\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1100). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5460 - accuracy: 0.7732 - val_loss: 0.6102 - val_accuracy: 0.7725\n","Epoch 21/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5434 - accuracy: 0.7719 - val_loss: 0.6067 - val_accuracy: 0.7713\n","Epoch 22/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5423 - accuracy: 0.7708 - val_loss: 0.4796 - val_accuracy: 0.7710\n","Epoch 23/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5472 - accuracy: 0.7712 - val_loss: 0.5198 - val_accuracy: 0.7712\n","Epoch 24/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5458 - accuracy: 0.7713 - val_loss: 0.5530 - val_accuracy: 0.7711\n","Epoch 25/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5445 - accuracy: 0.7709 - val_loss: 0.5402 - val_accuracy: 0.7709\n","Epoch 26/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5445 - accuracy: 0.7708 - val_loss: 0.5647 - val_accuracy: 0.7707\n","Epoch 27/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5441 - accuracy: 0.7705 - val_loss: 0.5907 - val_accuracy: 0.7702\n","Epoch 28/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5373 - accuracy: 0.7699 - val_loss: 0.5347 - val_accuracy: 0.7699\n","Epoch 29/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5410 - accuracy: 0.7699 - val_loss: 0.4890 - val_accuracy: 0.7700\n","Epoch 30/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5363 - accuracy: 0.7702 - val_loss: 0.5548 - val_accuracy: 0.7702\n","Epoch 31/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5390 - accuracy: 0.7701 - val_loss: 0.6588 - val_accuracy: 0.7695\n","Epoch 32/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5377 - accuracy: 0.7688 - val_loss: 0.4951 - val_accuracy: 0.7689\n","Epoch 33/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5383 - accuracy: 0.7690 - val_loss: 0.4803 - val_accuracy: 0.7691\n","Epoch 34/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5355 - accuracy: 0.7692 - val_loss: 0.4881 - val_accuracy: 0.7694\n","Epoch 35/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5324 - accuracy: 0.7696 - val_loss: 0.4688 - val_accuracy: 0.7698\n","Epoch 36/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5296 - accuracy: 0.7699 - val_loss: 0.5860 - val_accuracy: 0.7696\n","Epoch 37/200\n","3617/3617 [==============================] - 383s 106ms/step - loss: 0.5336 - accuracy: 0.7695 - val_loss: 0.5565 - val_accuracy: 0.7693\n","Epoch 38/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5305 - accuracy: 0.7693 - val_loss: 0.5913 - val_accuracy: 0.7691\n","Epoch 39/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5349 - accuracy: 0.7688 - val_loss: 0.4301 - val_accuracy: 0.7690\n","Epoch 40/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5360 - accuracy: 0.7693 - val_loss: 0.4482 - val_accuracy: 0.7694\n","Epoch 41/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5293 - accuracy: 0.7696 - val_loss: 0.5056 - val_accuracy: 0.7697\n","Epoch 42/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5324 - accuracy: 0.7698 - val_loss: 0.5206 - val_accuracy: 0.7698\n","Epoch 43/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5261 - accuracy: 0.7699 - val_loss: 0.5991 - val_accuracy: 0.7696\n","Epoch 44/200\n","3617/3617 [==============================] - 382s 106ms/step - loss: 0.5322 - accuracy: 0.7695 - val_loss: 0.4699 - val_accuracy: 0.7695\n","Epoch 45/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.5298 - accuracy: 0.7695 - val_loss: 0.5647 - val_accuracy: 0.7695\n","Epoch 46/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5302 - accuracy: 0.7693 - val_loss: 0.5903 - val_accuracy: 0.7691\n","Epoch 47/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5268 - accuracy: 0.7690 - val_loss: 0.5217 - val_accuracy: 0.7690\n","Epoch 48/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5284 - accuracy: 0.7691 - val_loss: 0.6227 - val_accuracy: 0.7688\n","Epoch 49/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5297 - accuracy: 0.7685 - val_loss: 0.5744 - val_accuracy: 0.7684\n","Epoch 50/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.5294 - accuracy: 0.7683 - val_loss: 0.5041 - val_accuracy: 0.7684\n","Epoch 51/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5269 - accuracy: 0.7684 - val_loss: 0.5201 - val_accuracy: 0.7684\n","Epoch 52/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5274 - accuracy: 0.7685 - val_loss: 0.4984 - val_accuracy: 0.7685\n","Epoch 53/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5295 - accuracy: 0.7686 - val_loss: 0.5462 - val_accuracy: 0.7686\n","Epoch 54/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5225 - accuracy: 0.7685 - val_loss: 0.4629 - val_accuracy: 0.7687\n","Epoch 55/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5276 - accuracy: 0.7688 - val_loss: 0.5146 - val_accuracy: 0.7688\n","Epoch 56/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5253 - accuracy: 0.7688 - val_loss: 0.5418 - val_accuracy: 0.7688\n","Epoch 57/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5244 - accuracy: 0.7688 - val_loss: 0.5208 - val_accuracy: 0.7688\n","Epoch 58/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5215 - accuracy: 0.7688 - val_loss: 0.7232 - val_accuracy: 0.7684\n","Epoch 59/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5233 - accuracy: 0.7680 - val_loss: 0.5617 - val_accuracy: 0.7680\n","Epoch 60/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5209 - accuracy: 0.7678 - val_loss: 0.4797 - val_accuracy: 0.7680\n","Epoch 61/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5186 - accuracy: 0.7681 - val_loss: 0.5059 - val_accuracy: 0.7681\n","Epoch 62/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5260 - accuracy: 0.7682 - val_loss: 0.5625 - val_accuracy: 0.7681\n","Epoch 63/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5222 - accuracy: 0.7680 - val_loss: 0.5926 - val_accuracy: 0.7679\n","Epoch 64/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5234 - accuracy: 0.7677 - val_loss: 0.5754 - val_accuracy: 0.7677\n","Epoch 65/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5170 - accuracy: 0.7676 - val_loss: 0.5136 - val_accuracy: 0.7676\n","Epoch 66/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5248 - accuracy: 0.7676 - val_loss: 0.5266 - val_accuracy: 0.7676\n","Epoch 67/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5220 - accuracy: 0.7676 - val_loss: 0.5992 - val_accuracy: 0.7675\n","Epoch 68/200\n","3617/3617 [==============================] - 381s 105ms/step - loss: 0.5158 - accuracy: 0.7674 - val_loss: 0.4942 - val_accuracy: 0.7674\n","Epoch 69/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.5232 - accuracy: 0.7675 - val_loss: 0.4937 - val_accuracy: 0.7675\n","Epoch 70/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5199 - accuracy: 0.7676 - val_loss: 0.5647 - val_accuracy: 0.7675\n","Epoch 71/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5141 - accuracy: 0.7675 - val_loss: 0.4673 - val_accuracy: 0.7676\n","Epoch 72/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5190 - accuracy: 0.7677 - val_loss: 0.4831 - val_accuracy: 0.7678\n","Epoch 73/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5189 - accuracy: 0.7678 - val_loss: 0.5939 - val_accuracy: 0.7677\n","Epoch 74/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5159 - accuracy: 0.7676 - val_loss: 0.5407 - val_accuracy: 0.7676\n","Epoch 75/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5161 - accuracy: 0.7676 - val_loss: 0.6004 - val_accuracy: 0.7675\n","Epoch 76/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5152 - accuracy: 0.7673 - val_loss: 0.6082 - val_accuracy: 0.7673\n","Epoch 77/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5171 - accuracy: 0.7671 - val_loss: 0.4952 - val_accuracy: 0.7672\n","Epoch 78/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5151 - accuracy: 0.7672 - val_loss: 0.4722 - val_accuracy: 0.7673\n","Epoch 79/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5135 - accuracy: 0.7673 - val_loss: 0.4398 - val_accuracy: 0.7675\n","Epoch 80/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5188 - accuracy: 0.7676 - val_loss: 0.4958 - val_accuracy: 0.7676\n","Epoch 81/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.5188 - accuracy: 0.7676 - val_loss: 0.5788 - val_accuracy: 0.7676\n","Epoch 82/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5211 - accuracy: 0.7675 - val_loss: 0.5518 - val_accuracy: 0.7675\n","Epoch 83/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5140 - accuracy: 0.7675 - val_loss: 0.4601 - val_accuracy: 0.7676\n","Epoch 84/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.5137 - accuracy: 0.7676 - val_loss: 0.4490 - val_accuracy: 0.7678\n","Epoch 85/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.5122 - accuracy: 0.7679 - val_loss: 0.6271 - val_accuracy: 0.7678\n","Epoch 86/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.5170 - accuracy: 0.7676 - val_loss: 0.4773 - val_accuracy: 0.7677\n","Epoch 87/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5108 - accuracy: 0.7678 - val_loss: 0.5468 - val_accuracy: 0.7678\n","Epoch 88/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.5110 - accuracy: 0.7678 - val_loss: 0.4916 - val_accuracy: 0.7678\n","Epoch 89/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.5105 - accuracy: 0.7679 - val_loss: 0.5919 - val_accuracy: 0.7678\n","Epoch 90/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5068 - accuracy: 0.7678 - val_loss: 0.5123 - val_accuracy: 0.7678\n","Epoch 91/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5137 - accuracy: 0.7678 - val_loss: 0.4940 - val_accuracy: 0.7678\n","Epoch 92/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5146 - accuracy: 0.7678 - val_loss: 0.5263 - val_accuracy: 0.7678\n","Epoch 93/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5082 - accuracy: 0.7678 - val_loss: 0.4482 - val_accuracy: 0.7680\n","Epoch 94/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5117 - accuracy: 0.7681 - val_loss: 0.4919 - val_accuracy: 0.7681\n","Epoch 95/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5138 - accuracy: 0.7682 - val_loss: 0.4939 - val_accuracy: 0.7682\n","Epoch 96/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5123 - accuracy: 0.7683 - val_loss: 0.4813 - val_accuracy: 0.7683\n","Epoch 97/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.5022 - accuracy: 0.7684 - val_loss: 0.5241 - val_accuracy: 0.7684\n","Epoch 98/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5109 - accuracy: 0.7685 - val_loss: 0.5275 - val_accuracy: 0.7684\n","Epoch 99/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5096 - accuracy: 0.7685 - val_loss: 0.5423 - val_accuracy: 0.7684\n","Epoch 100/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.5084 - accuracy: 0.7684 - val_loss: 0.4406 - val_accuracy: 0.7685\n","Epoch 101/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5106 - accuracy: 0.7686 - val_loss: 0.4739 - val_accuracy: 0.7687\n","Epoch 102/200\n","3617/3617 [==============================] - 382s 105ms/step - loss: 0.5069 - accuracy: 0.7687 - val_loss: 0.5033 - val_accuracy: 0.7688\n","Epoch 103/200\n","3617/3617 [==============================] - 381s 105ms/step - loss: 0.5025 - accuracy: 0.7688 - val_loss: 0.4539 - val_accuracy: 0.7689\n","Epoch 104/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.5096 - accuracy: 0.7690 - val_loss: 0.5722 - val_accuracy: 0.7689\n","Epoch 105/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5073 - accuracy: 0.7689 - val_loss: 0.5487 - val_accuracy: 0.7689\n","Epoch 106/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5055 - accuracy: 0.7689 - val_loss: 0.4764 - val_accuracy: 0.7689\n","Epoch 107/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5063 - accuracy: 0.7690 - val_loss: 0.5520 - val_accuracy: 0.7690\n","Epoch 108/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5052 - accuracy: 0.7690 - val_loss: 0.5326 - val_accuracy: 0.7689\n","Epoch 109/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5098 - accuracy: 0.7690 - val_loss: 0.5450 - val_accuracy: 0.7689\n","Epoch 110/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5059 - accuracy: 0.7689 - val_loss: 0.4429 - val_accuracy: 0.7690\n","Epoch 111/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5046 - accuracy: 0.7691 - val_loss: 0.4842 - val_accuracy: 0.7691\n","Epoch 112/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5050 - accuracy: 0.7692 - val_loss: 0.4447 - val_accuracy: 0.7692\n","Epoch 113/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5046 - accuracy: 0.7693 - val_loss: 0.5067 - val_accuracy: 0.7693\n","Epoch 114/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5006 - accuracy: 0.7694 - val_loss: 0.4871 - val_accuracy: 0.7694\n","Epoch 115/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.4996 - accuracy: 0.7695 - val_loss: 0.4660 - val_accuracy: 0.7695\n","Epoch 116/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5077 - accuracy: 0.7696 - val_loss: 0.4681 - val_accuracy: 0.7696\n","Epoch 117/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5061 - accuracy: 0.7697 - val_loss: 0.6785 - val_accuracy: 0.7696\n","Epoch 118/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5010 - accuracy: 0.7694 - val_loss: 0.4385 - val_accuracy: 0.7695\n","Epoch 119/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5005 - accuracy: 0.7695 - val_loss: 0.5315 - val_accuracy: 0.7696\n","Epoch 120/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.4984 - accuracy: 0.7696 - val_loss: 0.4950 - val_accuracy: 0.7696\n","Epoch 121/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5043 - accuracy: 0.7697 - val_loss: 0.5303 - val_accuracy: 0.7697\n","Epoch 122/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5008 - accuracy: 0.7697 - val_loss: 0.4793 - val_accuracy: 0.7697\n","Epoch 123/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5027 - accuracy: 0.7698 - val_loss: 0.6775 - val_accuracy: 0.7697\n","Epoch 124/200\n","3617/3617 [==============================] - 375s 104ms/step - loss: 0.5011 - accuracy: 0.7695 - val_loss: 0.5468 - val_accuracy: 0.7695\n","Epoch 125/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5026 - accuracy: 0.7695 - val_loss: 0.5213 - val_accuracy: 0.7695\n","Epoch 126/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4991 - accuracy: 0.7695 - val_loss: 0.4646 - val_accuracy: 0.7696\n","Epoch 127/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4992 - accuracy: 0.7697 - val_loss: 0.4897 - val_accuracy: 0.7697\n","Epoch 128/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.5001 - accuracy: 0.7697 - val_loss: 0.6327 - val_accuracy: 0.7697\n","Epoch 129/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5001 - accuracy: 0.7695 - val_loss: 0.5147 - val_accuracy: 0.7696\n","Epoch 130/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.5020 - accuracy: 0.7696 - val_loss: 0.5036 - val_accuracy: 0.7697\n","Epoch 131/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4976 - accuracy: 0.7697 - val_loss: 0.6517 - val_accuracy: 0.7696\n","Epoch 132/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4903 - accuracy: 0.7695 - val_loss: 0.5642 - val_accuracy: 0.7695\n","Epoch 133/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4995 - accuracy: 0.7694 - val_loss: 0.4567 - val_accuracy: 0.7695\n","Epoch 134/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5015 - accuracy: 0.7695 - val_loss: 0.5359 - val_accuracy: 0.7696\n","Epoch 135/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.4960 - accuracy: 0.7696 - val_loss: 0.4945 - val_accuracy: 0.7696\n","Epoch 136/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5000 - accuracy: 0.7697 - val_loss: 0.4774 - val_accuracy: 0.7697\n","Epoch 137/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5002 - accuracy: 0.7697 - val_loss: 0.5369 - val_accuracy: 0.7697\n","Epoch 138/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5002 - accuracy: 0.7698 - val_loss: 0.6567 - val_accuracy: 0.7696\n","Epoch 139/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5010 - accuracy: 0.7695 - val_loss: 0.4811 - val_accuracy: 0.7696\n","Epoch 140/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.4969 - accuracy: 0.7696 - val_loss: 0.5597 - val_accuracy: 0.7696\n","Epoch 141/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.4979 - accuracy: 0.7695 - val_loss: 0.5021 - val_accuracy: 0.7696\n","Epoch 142/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.4991 - accuracy: 0.7696 - val_loss: 0.5998 - val_accuracy: 0.7696\n","Epoch 143/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4994 - accuracy: 0.7695 - val_loss: 0.4853 - val_accuracy: 0.7696\n","Epoch 144/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.5005 - accuracy: 0.7696 - val_loss: 0.6255 - val_accuracy: 0.7696\n","Epoch 145/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4886 - accuracy: 0.7695 - val_loss: 0.4686 - val_accuracy: 0.7695\n","Epoch 146/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.5027 - accuracy: 0.7696 - val_loss: 0.5898 - val_accuracy: 0.7695\n","Epoch 147/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4986 - accuracy: 0.7695 - val_loss: 0.5813 - val_accuracy: 0.7695\n","Epoch 148/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.5004 - accuracy: 0.7694 - val_loss: 0.5102 - val_accuracy: 0.7694\n","Epoch 149/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4923 - accuracy: 0.7695 - val_loss: 0.5920 - val_accuracy: 0.7694\n","Epoch 150/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4973 - accuracy: 0.7694 - val_loss: 0.4484 - val_accuracy: 0.7695\n","Epoch 151/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.4961 - accuracy: 0.7695 - val_loss: 0.4583 - val_accuracy: 0.7696\n","Epoch 152/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4895 - accuracy: 0.7697 - val_loss: 0.4858 - val_accuracy: 0.7697\n","Epoch 153/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4952 - accuracy: 0.7697 - val_loss: 0.4960 - val_accuracy: 0.7698\n","Epoch 154/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4977 - accuracy: 0.7698 - val_loss: 0.5079 - val_accuracy: 0.7698\n","Epoch 155/200\n","3617/3617 [==============================] - 381s 105ms/step - loss: 0.4866 - accuracy: 0.7698 - val_loss: 0.4529 - val_accuracy: 0.7699\n","Epoch 156/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4969 - accuracy: 0.7700 - val_loss: 0.4971 - val_accuracy: 0.7700\n","Epoch 157/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4890 - accuracy: 0.7700 - val_loss: 0.4452 - val_accuracy: 0.7701\n","Epoch 158/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4959 - accuracy: 0.7702 - val_loss: 0.4392 - val_accuracy: 0.7702\n","Epoch 159/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4894 - accuracy: 0.7703 - val_loss: 0.5026 - val_accuracy: 0.7703\n","Epoch 160/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4960 - accuracy: 0.7703 - val_loss: 0.6625 - val_accuracy: 0.7702\n","Epoch 161/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4942 - accuracy: 0.7702 - val_loss: 0.6029 - val_accuracy: 0.7701\n","Epoch 162/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.4961 - accuracy: 0.7701 - val_loss: 0.5172 - val_accuracy: 0.7701\n","Epoch 163/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4942 - accuracy: 0.7701 - val_loss: 0.5559 - val_accuracy: 0.7701\n","Epoch 164/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4903 - accuracy: 0.7701 - val_loss: 0.4809 - val_accuracy: 0.7701\n","Epoch 165/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4921 - accuracy: 0.7702 - val_loss: 0.4637 - val_accuracy: 0.7702\n","Epoch 166/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4851 - accuracy: 0.7702 - val_loss: 0.4999 - val_accuracy: 0.7703\n","Epoch 167/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4927 - accuracy: 0.7703 - val_loss: 0.5280 - val_accuracy: 0.7703\n","Epoch 168/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4910 - accuracy: 0.7703 - val_loss: 0.5412 - val_accuracy: 0.7703\n","Epoch 169/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.4878 - accuracy: 0.7703 - val_loss: 0.5600 - val_accuracy: 0.7703\n","Epoch 170/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.4870 - accuracy: 0.7703 - val_loss: 0.4573 - val_accuracy: 0.7703\n","Epoch 171/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.4954 - accuracy: 0.7704 - val_loss: 0.4518 - val_accuracy: 0.7704\n","Epoch 172/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4901 - accuracy: 0.7705 - val_loss: 0.5392 - val_accuracy: 0.7705\n","Epoch 173/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4897 - accuracy: 0.7705 - val_loss: 0.5271 - val_accuracy: 0.7705\n","Epoch 174/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4918 - accuracy: 0.7705 - val_loss: 0.5196 - val_accuracy: 0.7705\n","Epoch 175/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4894 - accuracy: 0.7705 - val_loss: 0.5017 - val_accuracy: 0.7705\n","Epoch 176/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4912 - accuracy: 0.7705 - val_loss: 0.4976 - val_accuracy: 0.7706\n","Epoch 177/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.4930 - accuracy: 0.7706 - val_loss: 0.4968 - val_accuracy: 0.7706\n","Epoch 178/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4862 - accuracy: 0.7707 - val_loss: 0.4651 - val_accuracy: 0.7707\n","Epoch 179/200\n","3617/3617 [==============================] - 381s 105ms/step - loss: 0.4921 - accuracy: 0.7708 - val_loss: 0.6015 - val_accuracy: 0.7707\n","Epoch 180/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4900 - accuracy: 0.7707 - val_loss: 0.5017 - val_accuracy: 0.7707\n","Epoch 181/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4856 - accuracy: 0.7707 - val_loss: 0.4822 - val_accuracy: 0.7708\n","Epoch 182/200\n","3617/3617 [==============================] - 381s 105ms/step - loss: 0.4914 - accuracy: 0.7708 - val_loss: 0.5092 - val_accuracy: 0.7708\n","Epoch 183/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4903 - accuracy: 0.7708 - val_loss: 0.5023 - val_accuracy: 0.7709\n","Epoch 184/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.4901 - accuracy: 0.7709 - val_loss: 0.4883 - val_accuracy: 0.7709\n","Epoch 185/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.4898 - accuracy: 0.7709 - val_loss: 0.5328 - val_accuracy: 0.7709\n","Epoch 186/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4895 - accuracy: 0.7709 - val_loss: 0.5102 - val_accuracy: 0.7709\n","Epoch 187/200\n","3617/3617 [==============================] - 380s 105ms/step - loss: 0.4925 - accuracy: 0.7710 - val_loss: 0.4903 - val_accuracy: 0.7710\n","Epoch 188/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4857 - accuracy: 0.7710 - val_loss: 0.5232 - val_accuracy: 0.7710\n","Epoch 189/200\n","3617/3617 [==============================] - 379s 105ms/step - loss: 0.4869 - accuracy: 0.7710 - val_loss: 0.5536 - val_accuracy: 0.7710\n","Epoch 190/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.4957 - accuracy: 0.7710 - val_loss: 0.5072 - val_accuracy: 0.7710\n","Epoch 191/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4918 - accuracy: 0.7710 - val_loss: 0.4889 - val_accuracy: 0.7710\n","Epoch 192/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4874 - accuracy: 0.7710 - val_loss: 0.5319 - val_accuracy: 0.7711\n","Epoch 193/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4889 - accuracy: 0.7711 - val_loss: 0.5145 - val_accuracy: 0.7711\n","Epoch 194/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.4823 - accuracy: 0.7711 - val_loss: 0.5038 - val_accuracy: 0.7711\n","Epoch 195/200\n","3617/3617 [==============================] - 378s 104ms/step - loss: 0.4866 - accuracy: 0.7711 - val_loss: 0.5286 - val_accuracy: 0.7711\n","Epoch 196/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4843 - accuracy: 0.7711 - val_loss: 0.4429 - val_accuracy: 0.7712\n","Epoch 197/200\n","3617/3617 [==============================] - 376s 104ms/step - loss: 0.4876 - accuracy: 0.7712 - val_loss: 0.4818 - val_accuracy: 0.7713\n","Epoch 198/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4795 - accuracy: 0.7713 - val_loss: 0.5290 - val_accuracy: 0.7713\n","Epoch 199/200\n","3617/3617 [==============================] - 378s 105ms/step - loss: 0.4849 - accuracy: 0.7714 - val_loss: 0.5559 - val_accuracy: 0.7713\n","Epoch 200/200\n","3617/3617 [==============================] - 377s 104ms/step - loss: 0.4939 - accuracy: 0.7713 - val_loss: 0.5574 - val_accuracy: 0.7713\n","saving results...\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"fyRFxeEbxcmw","executionInfo":{"elapsed":7,"status":"error","timestamp":1627428129490,"user":{"displayName":"Amit Maraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIjxX64jgsJgA6plPfv8O9YGirFDRf37TMazVeEww=s64","userId":"07292138418067546452"},"user_tz":240},"outputId":"f9b890de-ad2c-4cf4-e424-5d34e8e02fbd"},"source":["from matplotlib import pyplot as plt\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"id":"fyRFxeEbxcmw","execution_count":null,"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5d7a4aa83693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}]},{"cell_type":"code","metadata":{"id":"2sVFESlTpQ18"},"source":[""],"id":"2sVFESlTpQ18","execution_count":null,"outputs":[]}]}